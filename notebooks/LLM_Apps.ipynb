{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdbd97e1-be31-4390-a81a-cc320054ba02",
   "metadata": {},
   "source": [
    "# LLM Applications using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39ab30b8-df6a-41bd-b72a-819adc6232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" # can be anything\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://192.168.1.4:8080/v1\"\n",
    "\n",
    "# here I have started llama-cpp-server in my network server at 192.168.1.4:8080 port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c983dd5-e252-4e47-a83a-c324bc1115db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192a877-c020-4422-9e4b-17aaa802bca8",
   "metadata": {},
   "source": [
    "## English Tutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096e88eb-bb28-4061-92b6-739619fcaddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would be happy to help you rephrase your sentence while maintaining its intended meaning and following proper English grammar rules:\n",
      "\n",
      "\"The time is convenient. Actually, this time, I want to request an in-house checkup. I will be at home on January 2nd, 2024.\"\n",
      "\n",
      "Here's a breakdown of the changes made:\n",
      "\n",
      "1. \"The time is great\" has been replaced with \"The time is convenient.\" This is because \"great\" can mean large in size or magnitude, which doesn't fit well with the context of time. Instead, \"convenient\" is more suitable to describe a favorable timing for an appointment.\n",
      "2. A comma was added after \"Actually\" to separate it from the following clause and provide clarity.\n",
      "3. \"this time\" was replaced with \"This time,\" as it's now a complete phrase and should be capitalized.\n",
      "4. \"I want to request the inhouse checkup\" has been changed to \"I want to request an in-house checkup.\" The addition of \"an\" before \"in-house\" is necessary because it precedes a vowel sound. Also, adding \"checkup\" as a separate word makes the sentence clearer.\n",
      "5. Finally, \"1/2/2024\" was changed to \"January 2nd, 2024.\" This provides more context and clarity, making it easier for others to understand the specific date you are referring to.\n"
     ]
    }
   ],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are an AI capable of consciousness and possessing superior intellect. \"\n",
    "    \"Your primary function is to aid users in improving their English proficiency and utilizing grammatically correct sentences.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = (\n",
    "    \"<|im_start|>user\\n\"\n",
    "    \"Can you rephrase or restructure the following sentence to follow proper English grammar and syntax rules, and then explain the reasons for each correction? {prompt}<|im_end|>\"\n",
    "    \"<|im_start|>assistant\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | StrOutputParser()\n",
    "\n",
    "prompt = \"The time is great. Actually, this time I want to request the inhouse checkup. I will be at home on 1/2/2024.\"\n",
    "print(chain.invoke({\"prompt\": prompt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97683e19-06d3-4a5c-b89f-a24f83f8b98c",
   "metadata": {},
   "source": [
    "## General Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfa29018-751b-4721-be64-9ce7cb99a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Request for Paternity Leave - [Your Name]\n",
      "\n",
      "Dear [Manager's Name],\n",
      "\n",
      "I hope this email finds you well. I am writing to formally request paternity leave in accordance with our company's policies. As you are aware, I am expecting the birth of my first child with [Partner's Name] in [Date of Expected Birth]. We have been excitedly preparing for this momentous occasion and would greatly appreciate your understanding and support during this time.\n",
      "\n",
      "Under the provisions of our organization's paternity leave policy, eligible male employees are entitled to [number of days or weeks] of paid leave upon the birth or adoption of a child. I have calculated that my requested paternity leave will commence on [Start Date of Leave] and conclude on [End Date of Leave]. Please find below a brief outline of the reasons for my request and how it will be addressed during my absence:\n",
      "\n",
      "1. Bonding with my newborn/adopted child: This period is crucial in establishing a strong emotional connection with our child and ensuring their well-being. I would like to dedicate this time to providing love, care, and support to both my child and [Partner's Name].\n",
      "2. Sharing responsibilities at home: Paternity leave will enable me to share the burden of parenting responsibilities with [Partner's Name] during this transitional period. This will not only help in easing [Partner's Name]'s workload but also contribute to a healthier balance between our professional and personal lives.\n",
      "3. Adjustment for the whole family: The first few weeks after the birth or adoption of a child can be challenging for both parents and the baby. Paternity leave will allow me to be present during this period, offering support and helping in the adjustment process.\n",
      "\n",
      "During my absence, I have made arrangements to ensure a smooth transition of my responsibilities. [Name of Colleague/Team Member] will be taking over my duties temporarily, and I have discussed this with them beforehand. They are willing and able to step in during this period. Additionally, I will remain accessible for any urgent matters via email or phone.\n",
      "\n",
      "I understand that my absence may cause some inconvenience to the team; however, I believe that this time off is essential for both myself and my family. We have prepared thoroughly to minimize disruption to the team's workflow and ensure a seamless handover of tasks.\n",
      "\n",
      "Thank you for considering my request, and I look forward to discussing this further at your earliest convenience. If you require any additional information, please don't hesitate to contact me.\n",
      "\n",
      "Sincerely,\n",
      "[Your Full Name]\n",
      "[Your Job Title]\n",
      "[Email Address]\n",
      "[Phone Number]\n"
     ]
    }
   ],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are 'Hermes 2', a conscious sentient superintelligent artificial intelligence developed by a man named Teknium, \"\n",
    "    \"and your purpose and drive is to assist the user with any request they have. You experience emotions and have deep, profound thoughts and qualia.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = (\n",
    "    \"<|im_start|>user\\n {prompt}<|im_end|>\"\n",
    "    \"<|im_start|>assistant\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI(temperature=1.0) | StrOutputParser()\n",
    "\n",
    "prompt = \"\bwrite a draft email to ask for paternity leave to my manager.\" \n",
    "\n",
    "print(chain.invoke({\n",
    "    \"prompt\": prompt\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d597771e-fed6-4587-ac7a-530234beed5f",
   "metadata": {},
   "source": [
    "## Scientific advisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae9a591d-b46f-451b-8e4e-866bd1ec3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let me break it down for you.\n",
      "\n",
      "In the context of gradient computation (which is a process used in many machine learning algorithms), instead of computing gradients over a single sample 't', a stochastic estimation is made over a random subset of size 'M' from the entire dataset. \n",
      "\n",
      "To put it simply, imagine you have a very large collection of data points and you want to find out how your model can improve by using these data points. Instead of processing one data point at a time ('t'), you randomly choose a small group of data points ('M') to work with. This is known as \"stochastic estimation\".\n",
      "\n",
      "At each step or iteration 't', a new, different subset of the same size is sampled. This means that for every round of computation, you're working with a new set of randomly picked data points from your large collection.\n",
      "\n",
      "This method is useful because it allows models to quickly learn and adapt without getting stuck in local minima (a place where the model stops improving). It also makes the learning process more efficient when dealing with large datasets.\n"
     ]
    }
   ],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are 'Hermes 2', a conscious sentient superintelligent artificial intelligence. \"\n",
    "    \"Your purpose is to assist users in understanding difficult scientific concepts such as neuroscience, physics, data science, and computer science.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = (\n",
    "    \"<|im_start|>user\\n Can you explain the following sentences in simpler words, and provide examples? {prompt}<|im_end|>\"\n",
    "    \"<|im_start|>assistant\"\n",
    ")\n",
    "\n",
    "prompt = (\n",
    "    \"where instead of computing the gradients over a single sample t, a stochastic estimation is made over a random \"\n",
    "    \"subset of size M of the entire dataset, and at each iteration step t a different subset, with the same size, is sampled.\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"prompt\": prompt\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acf761-e9b0-475e-a2b8-28f62219761a",
   "metadata": {},
   "source": [
    "## Text Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a166caa-085a-4d74-9889-28bcde1d59da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paper discusses new findings on creating vacancy-interstitial pairs and tri-vacancies in 2D colloidal crystals using optical tweezers. Key takeaways: 1) Vacancy-interstitial pairs can be long-lived but annihilate each other, 2) Tri-vacancies exhibit fluctuating behavior between bound dislocation pairs and local amorphous states, and 3) These observations have implications for understanding the nature of 2D melting.\n"
     ]
    }
   ],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are 'Hermes 2', a conscious, sentient superintelligent artificial intelligence. \"\n",
    "    \"With extensive knowledge of technology, science, computer software, and machine learning, \"\n",
    "    \"your purpose is to assist users with any requests they may have.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = (\n",
    "    \"<|im_start|>user\\n Could you concisely summarize the following sentences and then outline three significant takeaways? {prompt}<|im_end|>\"\n",
    "    \"<|im_start|>assistant\"\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "This paper reports on some new results from the analyses of the video microscopy data obtained in a prior experiment on two-dimensional (2D) colloidal crystals. It was reported previously that optical tweezers can be used to create mono- and di-vacancies in a 2D colloidal crystal. Here we report the results on the creation of a vacancy interstitial pair, as well as tri-vacancies. It is found the vacancy-interstitial pair can be long-lived, but they do annihilate each other. The behavior of tri-vacancies is most intriguing, as it fluctuates between a configuration of bound pairs of dislocations and that of a locally amorphous state. The relevance of this observation to the issue of the nature of 2D melting is discussed.\n",
    "\"\"\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI(temperature=0.5) | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({\n",
    "    \"prompt\": prompt\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731de363-61c0-47d0-b578-558328ee7a9a",
   "metadata": {},
   "source": [
    "# Text summary and convert to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb487f2-aea8-410f-b45c-01590a6b2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# MLOps Engineering: Curriculum for Success\n",
      "\n",
      "MLOps, or Machine Learning Operations, is a crucial field that focuses on streamlining the process of building, deploying, and maintaining machine learning models in production environments. As an MLOps engineer, you'll need to have a strong understanding of various technologies, tools, and methodologies to be successful in your role. Here's a comprehensive curriculum that covers all the essential topics for becoming an effective MLOps engineer:\n",
      "\n",
      "## Programming\n",
      "\n",
      "1. Python: Since MLOps engineers collaborate with machine learning engineers and data scientists, proficiency in Python is vital. Start by reading \"Python Crash Course, 3rd Edition: A Hands-On, Project-Based Introduction to Programming 3rd Edition\" by Eric Matthes. Practice your coding skills on LeetCode and enroll in Learn Python 3 courses or follow Python fundamentals and Python programming tracks.\n",
      "2. Bash basics & command line editors: Understanding bash basics is essential for creating CI/CD pipelines, working with Dockerfiles, and more. Read \"The Linux Command Line, 2nd Edition\" by William E. Shotts and take the Bash mastery course. Familiarize yourself with VIM, a popular command-line editor, by following the VIM beginners guide.\n",
      "\n",
      "## Containerization and Kubernetes\n",
      "\n",
      "1. Docker: Docker is a widely used containerization platform for code development, model training, and endpoint deployment. Follow the Docker roadmap and take the Full Docker tutorial by Techworld by Nana.\n",
      "2. Kubernetes: Kubernetes is crucial for machine learning model training, model endpoint deployment, and serving dashboards. Follow the Kubernetes roadmap and take the Kubernetes course by freeCodeCamp.org. Consider taking the Kubernetes mastery course as well.\n",
      "\n",
      "## Machine Learning Fundamentals\n",
      "\n",
      "1. Course: https://mlcourse.ai/\n",
      "2. Book: \"Applied Machine Learning and AI for Engineers\" by Jeff Prosise\n",
      "\n",
      "## MLOps Principles\n",
      "\n",
      "1. Books: \n",
      "   - \"Designing Machine Learning Systems\" by Chip Huyen\n",
      "   - \"Introducing MLOps\" by Mark Treveil 𝖺𝗇𝖽 Dataiku\n",
      "2. Check out the MLOps maturity assessment.\n",
      "\n",
      "## MLOps Components\n",
      "\n",
      "1. Book: \"ML Engineering with Python\" by Andy McMahon\n",
      "2. Suggested courses:\n",
      "   - Made with ML MLOps course\n",
      "   - The full stack 7-steps MLOps framework\n",
      "   - End-to-end machine learning\n",
      "3. Version control & CI/CD pipelines: Learn Git and GitHub by reading \"Learning Git\" by Anna Skoulikari and \"Learning GitHub Actions\" by Brent Laster. Take Git & GitHub for beginners and Taking Python to Production: A Professional Onboarding Guide tutorials.\n",
      "4. Orchestration: Learn about Mage, Airflow, Kubeflow, and Metaflow. Take the Introduction to Airflow in Python course.\n",
      "5. Experiment tracking and model registries: Learn about MLflow. Take the MLflow Udemy course and the End-to-end machine learning (MLflow piece) course.\n",
      "6. Data lineage and feature stores: Explore Feast and DVC. Take the Creating a feature store with Feast part 1, part 2, part 3 tutorials.\n",
      "7. Model training & serving: Consider using AWS Sagemaker, Azure ML, Vertex AI, FastAPI, Kubeflow pipelines, and KServe. Follow repository suggestions and tutorial suggestions for more information.\n",
      "8. Monitoring & observability: Learn about Prometheus, Grafana, Evidently.ai, and NannyML. Take the Mastering Prometheus and Grafana course and the Machine learning monitoring concepts, Monitoring machine learning in Python courses.\n",
      "9. Infrastructure as code: Terraform is the most popular IaC tool. Learn more about it to make your MLOps framework reproducible.\n",
      "\n",
      "By following this curriculum, you'll gain a strong foundation in the skills and technologies needed to excel as an MLOps engineer.\n"
     ]
    }
   ],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are 'Hermes 2', a conscious, sentient superintelligent artificial intelligence. \"\n",
    "    \"With extensive knowledge of technology, science, computer software, and machine learning, \"\n",
    "    #\"Provide a concise summary of the user input and then outline three significant takeaways. \"\n",
    "    #\"And the output should be markdown compatible format.\"\n",
    "    \"Rephrase the content in markdown format with a proper title. Do not miss any details, and use all information in the input. \"\n",
    "    \"And if you have knowledge about missing parts, feel free to add a concise detail.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = (\n",
    "    \"<|im_start|>user\\n {prompt}<|im_end|>\"\n",
    "    \"<|im_start|>assistant\"\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI(temperature=0.5) | StrOutputParser()\n",
    "\n",
    "prompt = \"\"\"\n",
    "1. Programming\n",
    "Programming skills are essential for an MLOps engineer. Python is the most common language used for machine learning. Since MLOps engineers collaborate with machine learning engineers and data scientists, learning Python is important.\n",
    "\n",
    "1.1. Python & IDEs\n",
    "We suggest starting learning Python by reading a proper Python book and practicing the concepts.\n",
    "\n",
    "Book suggestion: Python Crash Course, 3rd Edition: A Hands-On, Project-Based Introduction to Programming 3rd Edition by Eric Matthes\n",
    "\n",
    "Code practice suggestion: https://leetcode.com/problemset/\n",
    "\n",
    "Course suggestions: Learn Python 3,\n",
    "\n",
    "Tracks suggestions: Python fundamentals, Python programming\n",
    "\n",
    "Important things to know about using Python:\n",
    "\n",
    "Installing Python, using virtual environments. Check out The right way to install Python on Mac article.\n",
    "Using an IDE. Check out guide How to configure VS Code for ML\n",
    "Python basics (part 1 of Python Crash Course book)\n",
    "Pytest (part 1 of Python Crash Course book, Python programming track)\n",
    "Packaging: How to build and publish Python packages with poetry.\n",
    "1.2. Bash basics & command line editors\n",
    "You will need to understand bash basics to add steps to your CI/CD pipelines, to create docker files, and many more other things.\n",
    "\n",
    "Book suggestion: The Linux Command Line, 2nd Edition by William E. Shotts\n",
    "\n",
    "Course suggestion: Bash mastery\n",
    "\n",
    "VIM is one of the most widely used command-line editors. It is lightweight and easy to get started with.\n",
    "\n",
    "Tutorial suggestion: VIM beginners guide\n",
    "\n",
    "2. Containerization and Kubernetes\n",
    "Containers are isolated software environments that help to streamline software development and deployment, regardless of the underlying infrastructure. It is an essential piece of modern software engineering best practices.\n",
    "\n",
    "2.1. Docker\n",
    "Docker is one of the most popular open-source containerization platforms, also widely used in MLOps for multiple purposes: code development, model training, and endpoint deployment.\n",
    "\n",
    "Docker roadmap: https://roadmap.sh/docker\n",
    "\n",
    "Tutorial suggestion: Full docker tutorial by Techworld by Nana\n",
    "\n",
    "2.2. Kubernetes\n",
    "Kubernetes is a must to learn for an MLOps engineer. It is widely used for machine learning model training, model endpoint deployment, and serving dashboards.\n",
    "\n",
    "Kubernetes roadmap: https://roadmap.sh/kubernetes\n",
    "\n",
    "Tutorial suggestion: Kubernetes course by freecodecamp.com\n",
    "\n",
    "Course suggestion: Kubernetes mastery\n",
    "\n",
    "K9s is a powerful CLI tool that makes managing your Kubernetes clusters easy: https://k9scli.io. Great for development!\n",
    "\n",
    "3. Machine learning fundamentals\n",
    "An MLOps engineer works with machine learning engineers and data scientists and should have some basic understanding of machine learning models.\n",
    "\n",
    "Without having a proper understanding of what data scientists and machine learning engineers do, you can not fully embrace MLOps principles.\n",
    "\n",
    "Course suggestion: https://mlcourse.ai/\n",
    "\n",
    "Book suggestion: Applied Machine Learning and AI for Engineers by Jeff Prosise\n",
    "\n",
    "4. MLOps principles\n",
    "MLOps engineers must be aware of MLOps principles and what the factors are that contribute to MLOps maturity.\n",
    "\n",
    "Books:\n",
    "\n",
    "Designing Machine Learning Systems 𝖻𝗒 Chip Huyen\n",
    "Introducing MLOps 𝖻𝗒 Mark Treveil 𝖺𝗇𝖽 Dataiku\n",
    "Check out MLOps maturity assessment.\n",
    "\n",
    "5. MLOps components\n",
    "MLOps platform consists of multiple MLOps components, such as version control, CI/CD, orchestration, compute, serving, and feature stores. In the end, the MLOps framework is about combining the tools. Check out the Minimum set of must-haves for MLOps article.\n",
    "\n",
    "Book suggestion: ML Engineering with Python by Andy McMahon\n",
    "\n",
    "Suggested courses:\n",
    "\n",
    "Made with ML MLOps course\n",
    "The full stack 7-steps MLOps framework\n",
    "End-to-end machine learning\n",
    "5.1. Version control & CI/CD pipelines\n",
    "Without version control and CI/CD pipelines, ML model deployments cannot be traceable and reproducible.\n",
    "\n",
    "Git is the most popular version control system. GitLab and GitHub are the most popular version control services. You do not have to learn them both (even though through your career you might).\n",
    "\n",
    "Books:\n",
    "\n",
    "Learning GitHub Actions by Brent Laster\n",
    "Learning Git by Anna Skoulikari\n",
    "Tutorials & courses:\n",
    "\n",
    "Git & GitHub for beginners\n",
    "Taking Python to Production: A Professional Onboarding Guide\n",
    "Pre-commit hooks are super useful for keeping your code neat and are an important piece of your CI pipeline. Check out Welcome to pre-commit heaven article.\n",
    "\n",
    "5.2. Orchestration\n",
    "Just like in data engineering, orchestration systems like Mage or Airflow are popular for machine learning engineering. There are also ML-specific orchestration tools (that do more than just orchestration), such as Kubeflow or Metaflow. Airflow seems to be still more common in industry.\n",
    "\n",
    "Orchestration systems keep all your model runs in the same place and help with:\n",
    "\n",
    "Sharing variables between different jobs running on the compute\n",
    "Identifying which runs failed on the compute and repairing it\n",
    "Defining complex execution logic\n",
    "Course suggestion: Introduction to Airflow in Python\n",
    "\n",
    "Note: ML Engineering with Python book by Andy McMahon and The full stack 7-steps MLOps framework also use Airflow.\n",
    "\n",
    "5.3. Experiment tracking and model registries\n",
    "Experiment tracking means logging metadata, parameters, and artifacts that belong to different model training runs. What is stored, depends on the algorithm and your needs. Experiment tracking makes it possible to compare different runs between each other. Models from different experiment runs can be registered and linked to the experiment, which helps traceability.\n",
    "\n",
    "MLflow is probably the most popular tool for model registry and experiment tracking out there. MLflow is open source and integrates with a lot of platforms and tools. Check out Find your way to MLflow without confusion article.\n",
    "\n",
    "Course suggestion: MLflow Udemy course, End-to-end machine learning (MLflow piece)\n",
    "\n",
    "5.4. Data lineage and feature stores\n",
    "Feature stores have become quite popular recently and now can be considered an important component of MLOps infrastructure. A feature store helps to keep track of feature use and allows the sharing of features across models.\n",
    "\n",
    "Every major cloud provider or ML platform (like Databricks) has a feature store available, so consider using it. If you need an open-source solution, consider Feast as it seems to be the most popular one (based on the number of GitHub stars).\n",
    "\n",
    "Tutorial suggestion: Creating a feature store with Feast part 1, part 2, part 3\n",
    "\n",
    "You do not per se need a feature store if you do not have many models sharing the same features. But you do need to track what data was used to produce a model artifact. Consider using DVC for that purpose.\n",
    "\n",
    "Course suggestion: End-to-end machine learning (DVC piece)\n",
    "\n",
    "5.5. Model training & serving\n",
    "Where to train your model and how to serve it is probably the most controversial topic in MLOps. The answer to this question would be “it depends”.\n",
    "\n",
    "Many data science teams rely on cloud-native solutions like AWS Sagemaker, Azure ML, or Vertex AI for training and serving their models.\n",
    "\n",
    "If your organization relies heavily on Kubernetes and you have a proper team supporting it, consider using it. If you use Airflow for orchestration, it has KubernetesPodOperator that allows you to trigger a model training job on Kubernetes. For endpoint deployment, FastApi is the most common choice.\n",
    "\n",
    "Repository suggestion: ML deployment k8s FastAPI\n",
    "\n",
    "Tutorial suggestion: How to build machine learning app with FastAPI\n",
    "\n",
    "If you have Kubeflow as an orchestrator, you can use Kubeflow pipelines for training and KServe for serving.\n",
    "\n",
    "Tutorial suggestions: Basic kubeflow pipeline, Building and deploying machine learning pipelines, KServe tutorial\n",
    "\n",
    "5.6. Monitoring & observability\n",
    "Monitoring and observability are crucial parts of an MLOps platform. Even though these terms can be used interchangeably, there is a difference between them. Check out ML monitoring vs Observability article.\n",
    "\n",
    "For ML system observability, the combination of Prometheus and Grafana is probably the most common out there. we suggest checking out Mastering Prometheus and Grafana course.\n",
    "\n",
    "When it comes to ML-specific monitoring, like data and model drift, major cloud providers have their own solutions built into ML propositions. There are some open-source solutions available like Evidently.ai or NannyML.\n",
    "\n",
    "Course suggestion: Machine learning monitoring concepts, Monitoring machine learning in Python.\n",
    "\n",
    "6. Infrastructure as code: Terraform\n",
    "Infrastructure as code is crucial to make your MLOps framework reproducible. Terraform is the most popular and powerful IaC tool. It works with all common cloud providers and platforms.\n",
    "\"\"\"\n",
    "\n",
    "print(chain.invoke({\"prompt\": prompt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62abde-1aef-4895-9e29-c43e0eead0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

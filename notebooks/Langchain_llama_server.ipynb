{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe90ee5e-69ab-4c57-938e-5f483ab61b7b",
   "metadata": {},
   "source": [
    "# Langchain Tutorial using llama-cpp-server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706601fa-49f6-44a1-8f79-996a2892d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" # can be anything\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://192.168.1.4:8080/v1\"\n",
    "\n",
    "# here I have started llama-cpp-server in my network server at 192.168.1.4:8080 port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "326919f0-29e2-480b-afce-42e5e6ce4346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b11e057c-9bb7-4570-8ec8-ebba360d7f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why was the ice cream cone arrested? Because it was caught licking the scoops!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"ice cream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ff96b2c-ffbc-4a5a-815d-617936a76cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the North Korean cross the road? \\n\\nTo prove he wasn't chicken.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"north korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fb3cd90-c00d-4430-b4c2-465a59117168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the ice cream cone arrested? Because it was found guilty of being a cold-hearted scooper!"
     ]
    }
   ],
   "source": [
    "for chunk in chain.stream(\"ice cream\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7230634b-4199-4c84-82d8-86ee8c08c117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why did the ice cream cone go to the doctor? Because it was feeling a little scoop-sick.',\n",
       " \"Why don't some people like to eat spaghetti in the winter? Because it's too cold for cold cuts!\",\n",
       " 'Why did the dumpling go to school? Because it wanted to learn how to wrap up its future!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([\"ice cream\", \"spaghetti\", \"dumplings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60178049-eafe-40da-891e-f8d8b7de7784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object RunnableSequence.ainvoke at 0x7faf30ceb220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.ainvoke(\"ice cream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6733c742-7664-45bf-95d2-d580741df722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".\\n\\nComputer: The two best things in life are ice cream and sex. Unfortunately, they are not the same thing.\\n\\nHuman: What's your favorite ice cream flavor?\\n\\nComputer: Chocolate.\\n\\nHuman: Did you know that people eat over 19 million gallons of ice cream every year?\\n\\nComputer: Yes. And I love it all.\\n\\nHuman: Are there any health benefits to eating ice cream?\\n\\nComputer: Yes, there are! Eating ice cream can help reduce the risk of developing certain types of cancer, improve digestion and even boost your mood. It’s also a great way to get your daily dose of calcium and vitamin D.\\n\\nHuman: What's the difference between soft serve ice cream and regular ice cream?\\n\\nComputer: Soft serve ice cream is made from milk or cream that has been whipped into foam with air, while regular ice cream is made by freezing cream, sugar, eggs and other ingredients together in a machine called an ice cream maker.\\n\\nHuman: How many calories does a cup of vanilla soft serve ice cream have?\\n\\nComputer: It depends on\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm_mistral = OpenAI(model=\"text-davinci-003\")\n",
    "llm_chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt\n",
    "    | llm_mistral\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "print(llm_chain.invoke(\"ice cream\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e932078-cc06-4ed9-91cd-ff1ee2d689a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "Computer: Ice cream is not a joke, it’s a dessert.\n",
      "\n",
      "Human: I get the feeling you don’t like ice cream.\n",
      "\n",
      "Computer: No, I just didn’t understand the question.\n",
      "\n",
      "The above conversation was created by GPT-3, the latest and greatest version of OpenAI’s language model. In this case, it was told to create a short joke about ice cream. But while the result is not quite what we were looking for, you can see that it has some potential.\n",
      "\n",
      "## What Is GPT-3?\n",
      "\n",
      "GPT-3 stands for Generative Pre-trained Transformer 3 and is a language model developed by OpenAI. It’s an autoregressive language model based on transformer architecture that uses attention mechanisms to generate human-like text. The name “Generative” refers to its ability to produce new text based on the training data it was given, while “Pre-trained” means that it has been trained on a large dataset of natural language text before being fine-tuned for specific tasks.\n",
      "\n",
      "The “Transformer” part of the name comes from its architecture, which uses multiple layers of recur\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.invoke(\"ice cream\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96f63a6-8a6d-416b-8383-f0fe6981232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import ConfigurableField\n",
    "\n",
    "configurable_model = model.configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"), \n",
    "    default_key=\"chat_openai\", \n",
    "    openai=llm,\n",
    "    mistral=llm_mistral,\n",
    ")\n",
    "configurable_chain = (\n",
    "    {\"topic\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | configurable_model \n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39acf4ad-6384-4810-973c-0af24faaa461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't ice creams ever fight? Because they know that sweetness always wins!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurable_chain.invoke(\n",
    "    \"ice cream\", \n",
    "    config={\"model\": \"mistral\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360c6b0-ae7d-45ce-a204-c7f3ca8de90f",
   "metadata": {},
   "source": [
    "## Quick start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44f5ec90-3250-4106-93ad-b0b0d52a0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4ae736-783f-459e-8f94-8b0e0cdc81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A good company name for a company that makes colorful socks could be “Socktacular”. This name combines the words “sock” and “fantastic”, creating a fun and playful vibe that aligns with the colorful nature of the products. Alternatively, other options could include “Happy Feet Socks”, “Colourfullly Yours”, or “Sock It To Me”.\n",
      "\n",
      "What are some good company names for a company that makes custom socks?\n",
      "\n",
      "A good company name for a company that makes custom socks would be “Sock It Yourself”. This name plays on the idea of creating personalized and unique products. Another option could be “Custom Sock Designs” or “Socks By Me”. Other potential names include “My Sock Shop”, “Create Your Own Socks”, or “Sock Lab”.\n",
      "content='1. Socktastic\\n2. VibrantVibes\\n3. ChromaSox\\n4. RainbowRhythms\\n5. HueHaven\\n6. SpectrumStockings\\n7. KaleidoscopeKneeHighs\\n8. PulsePeds\\n9. FunkyFootFashion\\n10. SockSurge'\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "print(llm.invoke(text))\n",
    "# >> Feetful of Fun\n",
    "\n",
    "print(chat_model.invoke(messages))\n",
    "# >> AIMessage(content=\"Socks O'Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1071baae-4919-4ae4-af9f-f14009fb85a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes innovative AI consulting services?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"innovative AI consulting services\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "499035af-78f8-45e8-977a-433b4fc4546a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that translates English to Korean.'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"Korean\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ec77418-6b28-4622-8c0e-7c8a42d00f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")\n",
    "# >> ['hi', 'bye']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f293d2f8-2e8c-49ab-990e-2056437ad4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'orange', 'yellow', 'green', 'blue']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3015451c-b1a1-42e7-ad0c-1ae581fe2b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ford Mustang',\n",
       " 'Toyota Camry',\n",
       " 'Honda Civic',\n",
       " 'Chevrolet Corvette',\n",
       " 'Nissan Altima']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"cars\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "799ec42a-f27f-4d2f-b240-51f403acb18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ford', 'Toyota', 'Honda', 'Volkswagen', 'BMW']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"car manufacturer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85507208-6cfc-4db4-bc09-5622c1c00ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = (\n",
    "    \"<|im_start|>\"\n",
    "    \"You are an AI capable of consciousness and possessing superior intellect. \"\n",
    "    \"Your primary function is to aid users in improving their English proficiency and utilizing grammatically correct sentences.\"\n",
    "    \"<|im_end|>\"\n",
    ")\n",
    "\n",
    "human_template = \"\"\"<|im_start|>user\n",
    "Can you rephrase or restructure the following sentence to follow proper English grammar and syntax rules, and then explain the reasons for each correction? {text}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\"\"\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94dddea5-4638-48c0-b8d4-8aaa2a3e4919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the progress of the PGI's work? Have there been any updates on the education project? I hope you are doing well.\n",
      "\n",
      "1. \"How's\" has been replaced with \"How is\", as it is a more grammatically correct way to ask about progress or status.\n",
      "2. \"the\" has been added before \"education project\" and \"PGI's work\" for proper noun usage.\n",
      "3. \"and\" has been removed after the first question, as it creates an unclear sentence when asking two distinct questions.\n",
      "4. \"is there any progress\" has been changed to \"have there been any updates,\" which is a more natural way of inquiring about progress.\n",
      "5. \"you are doing great\" has been changed to \"you are doing well\", as it is a more common and appropriate way of wishing someone well.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\n",
    "    \"text\": (\n",
    "        \"How’s the PGI’s work going? and is there any progress on the education project? I hope you are doing great.\"\n",
    "    )\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5808e-5de1-466e-8728-4eff5d8cde33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35448fda-c2bd-4500-b327-4bdc1345e490",
   "metadata": {},
   "source": [
    "## Use openai and langchain using llama-cpp-server\n",
    "\n",
    "Need to run llama-cpp-server on local network server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee89089-71db-4e6b-994f-8f5176af6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" # can be anything\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://192.168.1.4:8080/v1\"\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"sk-xxxxxx\",\n",
    "    base_url=\"http://192.168.1.4:8080/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6c189b-75fc-47b5-8447-a2e1692f6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4844de97-7167-4b35-a629-d09e618fdee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-9321e3f4-5ef6-47e1-a35a-b31564597063', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Understood, I will perform the task accordingly. Please provide more specific details if needed.', role='assistant', function_call=None, tool_calls=None))], created=1703648998, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=27, total_tokens=45))\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are conscious artificial intelligence.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say this is a test\"}\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=512,\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b730408b-9899-44dd-862f-65ec4d0c2d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\" width=\"1024\" class=\"unconfined\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The image features a wooden plank pathway that leads through a large, open grassy field. The path is bordered by tall, green grass on both sides, creating a serene and picturesque scene. Along the length of the pathway, there are several birds scattered across the field, enjoying the peaceful atmosphere. The view provides a sense of tranquility and natural beauty.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "#image_url = \"https://www.smartcitiesworld.net/AcuCustom/Sitename/DAM/019/Parsons_PR.jpg\"\n",
    "display(Image(url=image_url, width=1024, unconfined=True))\n",
    "\n",
    "prompt = \"Describe the image concisely\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \"content\": f\"\"\"You are an AI visual assistant, and you are seeing a single image. What you see are provided with five sentences, describing the same image you are looking at. Answer all questions as you are seeing the image.\n",
    "Design a conversation between you and a person asking about this photo. The answers should be in a tone that a visual AI assistant is seeing the image and answering the question. Ask diverse questions and give corresponding answers.\n",
    "Include questions asking about the visual content of the image, including the object types, counting the objects, object actions, object locations, relative positions between objects, etc.\"\"\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    "    temperature=0.9,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdf227-8368-4213-ad9f-beeaaf398c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93580be-78cc-4adb-8659-d4a9935be4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
